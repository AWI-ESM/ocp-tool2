{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "ec6aa72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "'''\n",
    "The OpenIFS coupling preparation tool (ocp-tool) prepares input files for a\n",
    "coupled OpenIFS-FESOM2 or OpenIFS-NEMO climate simulation\n",
    "\n",
    "\n",
    "To this end it performs three tasks:\n",
    "1) Modifing the OpenIFS input files to fit the land sea mask and soil types\n",
    "    to the ocean models land sea mask\n",
    "2) Generating appropriate OASIS3-MCT input files to fit the modified land\n",
    "    sea mask\n",
    "3) Modifing the runoff-mapper drainage basin and arrival point file to fit\n",
    "    the modified land sea mask\n",
    "\n",
    "\n",
    "To function, the script therefore needs the following input files:\n",
    "1) Grid information txt file for the full Gaussian grid of the chosen\n",
    "    trucation number. This fileset comes with the tool.\n",
    "2) Grid information txt file for the reduced Gaussian grid This fileset comes\n",
    "    with the tool.\n",
    "3) OpenIFS gridpoint input file (ICMGG${EXP_NAME}INIT) containing default\n",
    "    land-sea mask that will be modified. can be requested from ECMWF:\n",
    "    openifs-support@ecmwf.int\n",
    "4) Runoff-mapper input files (runoff_maps.nc) file containing default\n",
    "    drainage basin and arrival point fields. This fileset is part of the\n",
    "    EC-Earth input files and available from:\n",
    "\n",
    "\n",
    "If you have trouble getting this tool to work in your python environment\n",
    "you may try loading the environment.yaml with:\n",
    "    conda env create -f environment.yml\n",
    "\n",
    "\n",
    "@author: Jan Streffing (jan.streffing@awi.de), August 2019\n",
    "'''\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gribapi\n",
    "import csv\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from netCDF4 import Dataset\n",
    "from shutil import copy2\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# Setup\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "# Setting constants\n",
    "earth_radius = 6371. * 1e3 #[m]\n",
    "longline = ' \\n ==================================================  \\n'\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# Function definitions\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "def read_grid_file(res_num, input_path_reduced_grid, input_path_full_grid, truncation_type, exp_name_oifs='hagw', input_path_oifs='input/openifs_input_default/',verbose=False):\n",
    "    '''\n",
    "    This function reads the reduced gaussian gridfile and returns it as a raw\n",
    "    field\n",
    "    '''\n",
    "    if truncation_type == 'linear':\n",
    "        # linear truncation (T = NN * 2 - 1)\n",
    "        NN = res_num/2 + 0.5\n",
    "        grid_txt = '%s/n%d_reduced.txt' % (input_path_reduced_grid, NN)\n",
    "        \n",
    "    elif truncation_type == 'cubic-octahedral':\n",
    "        # cubic octahedral truncation (T = NN - 1)\n",
    "        NN = res_num + 1\n",
    "        grid_txt = '%s/o%d_reduced.txt' % (input_path_reduced_grid, NN)\n",
    "\n",
    "    #print(' Read grid from file: %s ' % (grid_txt,) )\n",
    "\n",
    "    print(longline)\n",
    "    print(' Reading OpenIFS gridfile for T%d ' % (res_num))\n",
    "    print(longline)\n",
    "    \n",
    "    if os.path.isfile(grid_txt):\n",
    "       fin = open(grid_txt, 'r')\n",
    "       print(' Read grid from file: %s ' % (grid_txt,) )\n",
    "    else:\n",
    "       icmfile = '%s/ICMGG%sINIT' % (input_path_oifs, exp_name_oifs) \n",
    "       grid_txt = read_grid_from_icmgg(icmfile, NN, truncation_type)\n",
    "       fin = open(grid_txt, 'r')\n",
    "       print(' Read grid from file: %s ' % (icmfile,) )\n",
    "\n",
    "       \n",
    "    lines = fin.readlines()\n",
    "    return (lines, NN)\n",
    "\n",
    "\n",
    "def read_grid_from_icmgg(icmfile, NN, truncation_type):\n",
    "   \"\"\"\n",
    "   Read lon, lats from grib template file\n",
    "   Uses CDO to get grid description from a GRIB file\n",
    "   \"\"\"\n",
    "   \n",
    "   latitudes = []\n",
    "   nlongitudes = []\n",
    "   \n",
    "   file=icmfile\n",
    "   \n",
    "   # write grid description to file\n",
    "   # only need to do this once\n",
    "   os.system('cdo griddes %s > griddes.txt' % (file,))\n",
    "   \n",
    "   # read data from text file\n",
    "   f = open('griddes.txt','r')\n",
    "   lines = f.readlines()   \n",
    "   for i in range(0,len(lines)):      \n",
    "      if 'yvals' in lines[i]:\n",
    "         yline = i\n",
    "      elif 'rowlon' in lines[i] or 'reducedPoints' in lines[i]:\n",
    "         rline = i\n",
    "   \n",
    "   # read from yvals until we hit rowlon   \n",
    "   for i in range(yline,len(lines)):\n",
    "      line = lines[i]\n",
    "      print(line)\n",
    "      if 'rowlon' in line or 'reducedPoints' in line:\n",
    "         break\n",
    "      if i == yline:\n",
    "         # convert data to floats\n",
    "         tmp_lat = [float(lat) for lat in line.split()[2:]]\n",
    "      else:\n",
    "         tmp_lat = [float(lat) for lat in line.split()]\n",
    "      # append data to latitudes list\n",
    "      for lat in tmp_lat: latitudes.append(lat) \n",
    "      \n",
    "   for i in range(rline,len(lines)):\n",
    "      line = lines[i]\n",
    "      if 'scanningMode' in line: \n",
    "         break \n",
    "      if i == rline:\n",
    "         # convert to integers\n",
    "         tmp_nlon = [int(nlon) for nlon in line.split()[2:]]\n",
    "      else:\n",
    "         tmp_nlon = [int(nlon) for nlon in line.split()]\n",
    "      # append data to nlongitudes list\n",
    "      for nlon in tmp_nlon: nlongitudes.append(nlon) \n",
    "         \n",
    "   f.close()\n",
    "   \n",
    "   print('nlon: ',nlongitudes)\n",
    "   print('lat: ',latitudes)\n",
    "   \n",
    "   # Now construct the grid\n",
    "   lons = []\n",
    "   lats = []\n",
    "   for ilat in range(0,len(nlongitudes)):\n",
    "      \n",
    "      lat  = latitudes[ilat]\n",
    "      nlon = nlongitudes[ilat]\n",
    "      \n",
    "      lon1  = np.arange(0,360,360./nlon)\n",
    "      \n",
    "      for lon in lon1: \n",
    "         lons.append(lon)\n",
    "         lats.append(lat)   \n",
    "   \n",
    "   if truncation_type == 'cubic-octahedral':\n",
    "      ngrid = 'o%d' % (NN,)\n",
    "      rfile = 'input/gaussian_grids_octahedral_reduced/%s_reduced.txt' % (ngrid,)\n",
    "      \n",
    "   elif truncation_type == 'linear':\n",
    "      ngrid = 'n%d' % (NN,)\n",
    "      rfile = 'input/gaussian_grids_linear_reduced/%s_reduced.txt' % (ngrid,)\n",
    "   \n",
    "   # Write to text file that CDO can use for interpolations\n",
    "   f = open(rfile,'w')\n",
    "   f.write('latitude reduced regular latitude \\n')\n",
    "   f.write('number points points \\n')\n",
    "   f.write(' ------- ------- ------- ---------- \\n' )\n",
    "   \n",
    "   for ilat in range(0,len(nlongitudes)):\n",
    "      f.write('%d %d %d %f \\n' % (ilat+1, nlongitudes[ilat], len(nlongitudes)*2, latitudes[ilat]))\n",
    "   f.close()\n",
    "   \n",
    "   return rfile\n",
    "\n",
    "\n",
    "def extract_grid_data(lines,verbose=False):\n",
    "    '''\n",
    "    This function takes the raw reduced gaussian coordinate list and returns\n",
    "    coordinate and neighbour distrance lists for latitude and\n",
    "    longitude of every grindpoint, as well as the number of latitudes and\n",
    "    longitudes\n",
    "    '''\n",
    "    gridsize = 0\n",
    "    lons_list       = []  # longitudes of each gridpoint\n",
    "    lats_list       = []  # latitudes of each gridpoint\n",
    "    numlons_list    = []  # number of longitude points for each latitude\n",
    "    dlon_list       = []  # longitude distance in degree at each latitude\n",
    "    lat_list        = []  # list of latitudes\n",
    "\n",
    "    for line in lines[3:]:\n",
    "        # read latitude number, number of longitudes for red. Gaussian and regular Gauss grids\n",
    "        # convert from strings to floats\n",
    "        if verbose:\n",
    "            print(line)\n",
    "        _, red_points, _, lat = (float(z) for z in line.split())\n",
    "\n",
    "        # longitudes for reduced Gaussian grid\n",
    "        dlon = float(360)/red_points\n",
    "        #The -0.000000001 deals with rounding errors a la 360./644*360=359.9999999999994\n",
    "        lons = np.arange(0, 360-0.000000001, dlon)\n",
    "        numlons_list.append(int(red_points))\n",
    "        dlon_list.append(dlon)\n",
    "        lat_list.append(lat)\n",
    "\n",
    "        # set longitudes/latitudes for reduced Gaussian grid on this latitude\n",
    "        lons_list.extend(lons)\n",
    "        lats_list.extend([lat]*len(lons))\n",
    "        gridsize += len(lons)\n",
    "\n",
    "    return (lons_list, lats_list, numlons_list, dlon_list, lat_list)\n",
    "\n",
    "\n",
    "def calculate_corner_latlon(lats_list, lons_list, numlons_list, dlon_list,\n",
    "                            lat_list,verbose=False):\n",
    "    '''\n",
    "    This function calculates the latitude and longitude values at the corners\n",
    "    of the gridcells based on the center values. It also saves both the corner\n",
    "    and center coordinates into a float32 arrays with oasis3-mct compatible\n",
    "    structure\n",
    "    '''\n",
    "\n",
    "    # OASIS requires grids to be 2D, but IFS grid is 1D, so we give it an\n",
    "    # extra dimension.\n",
    "    center_lons = np.array(lons_list, dtype='float32')[np.newaxis, :]\n",
    "    center_lats = np.array(lats_list, dtype='float32')[np.newaxis, :]\n",
    "    nx = center_lons.shape[1]\n",
    "    ny = 1\n",
    "\n",
    "    print(' Size of grid: nx = %d, ny = %d' % (nx, ny))\n",
    "\n",
    "    # Now we calculate longitudes/latitudes of corner points for each grid cell\n",
    "    crn_lons = np.zeros((4, ny, nx))\n",
    "    crn_lats = np.zeros((4, ny, nx))\n",
    "\n",
    "    kk = 0 # cell index\n",
    "    for ii, ni in enumerate(numlons_list):\n",
    "        '''\n",
    "        Layout of the four corners\n",
    "\n",
    "        2 ---------- 1\n",
    "        |            |\n",
    "        |            |\n",
    "        |            |\n",
    "        3 -----------4\n",
    "\n",
    "        ^ y\n",
    "        |\n",
    "        |\n",
    "        |\n",
    "        ----> x\n",
    "        '''\n",
    "\n",
    "        dlon = dlon_list[ii]\n",
    "        lat  = lat_list[ii]\n",
    "        lons = np.arange(0, 360, dlon)\n",
    "\n",
    "        #     NP --- j=1 ---|--- j=2 ---|--- j=3 ---|--- j=n --- SP\n",
    "        #                           <-dlat_n-> <-dlat_s->\n",
    "\n",
    "        # if first latitude, the previous point was north pole\n",
    "        if ii == 0:\n",
    "            dlat_n = 90 - lat\n",
    "            dlat_s = (lat - lat_list[ii+1]) / 2.\n",
    "\n",
    "        # if last latitude, the next point is south pole\n",
    "        elif ii == len(numlons_list)-1:\n",
    "            dlat_n = (lat_list[ii-1] - lat) / 2.\n",
    "            dlat_s = lat + 90\n",
    "\n",
    "        else:\n",
    "            dlat_n = (lat_list[ii-1] - lat) / 2.\n",
    "            dlat_s = (lat - lat_list[ii+1]) / 2.\n",
    "\n",
    "        for jj in range(ni):\n",
    "            # corner 1: north-east\n",
    "            crn_lons[0, 0, kk] = lons[jj] + dlon/2.\n",
    "            crn_lats[0, 0, kk] = lat + dlat_n\n",
    "\n",
    "            # corner 2: north-west\n",
    "            crn_lons[1, 0, kk] = lons[jj] - dlon/2.\n",
    "            crn_lats[1, 0, kk] = lat + dlat_n\n",
    "\n",
    "            # corner 3: south-west\n",
    "            crn_lons[2, 0, kk] = lons[jj] - dlon/2.\n",
    "            crn_lats[2, 0, kk] = lat - dlat_s\n",
    "\n",
    "            # corner 4: south-east\n",
    "            crn_lons[3, 0, kk] = lons[jj] + dlon/2.\n",
    "            crn_lats[3, 0, kk] = lat - dlat_s\n",
    "\n",
    "            kk += 1\n",
    "\n",
    "    # Make sure that longitudes are [-180, 180] and not [0, 360]\n",
    "    center_lons = np.where( center_lons > 180, center_lons - 360, center_lons )\n",
    "    crn_lons    = np.where( crn_lons > 180, crn_lons - 360, crn_lons )\n",
    "    return (center_lats, center_lons, crn_lats, crn_lons)\n",
    "\n",
    "\n",
    "def calculate_area(center_lons, numlons_list, dlon_list, lat_list,verbose=False):\n",
    "    '''\n",
    "    This function calculates the area of the gridcells based on the center\n",
    "    values and saves them into a float32 array with oasis3-mct compatible\n",
    "    structure\n",
    "    '''\n",
    "\n",
    "    # OASIS requires grids to be 2D, but IFS grid is 1D, so we give it an\n",
    "    # extra dimension.\n",
    "    nx = center_lons.shape[1]\n",
    "    ny = 1\n",
    "\n",
    "     # Now we calculate the cell area of each cell\n",
    "    gridcell_area = np.zeros((ny, nx))\n",
    "\n",
    "    kk = 0 # cell index\n",
    "    for ii, ni in enumerate(numlons_list):\n",
    "\n",
    "        dlon = dlon_list[ii]\n",
    "        lat  = lat_list[ii]\n",
    "        lons = np.arange(0, 360, dlon)\n",
    "\n",
    "        #     NP --- j=1 ---|--- j=2 ---|--- j=3 ---|--- j=n --- SP\n",
    "        #                           <-dlat_n-> <-dlat_s->\n",
    "\n",
    "        # if first latitude, the previous point was north pole\n",
    "        if ii == 0:\n",
    "            dlat_n = 90 - lat\n",
    "            dlat_s = (lat - lat_list[ii+1]) / 2.\n",
    "\n",
    "        # if last latitude, the next point is south pole\n",
    "        elif ii == len(numlons_list)-1:\n",
    "            dlat_n = (lat_list[ii-1] - lat) / 2.\n",
    "            dlat_s = lat + 90\n",
    "\n",
    "        else:\n",
    "            dlat_n = (lat_list[ii-1] - lat) / 2.\n",
    "            dlat_s = (lat - lat_list[ii+1]) / 2.\n",
    "\n",
    "        # Grid cell areas in m2 width in latitude of cell is dlat_n + dlat_s\n",
    "        dx = dlon * np.pi/180. * earth_radius * np.cos( np.pi/180. * lat )\n",
    "        dy = (dlat_n + dlat_s) * np.pi/180. * earth_radius\n",
    "        area = dx * dy\n",
    "\n",
    "        for jj in range(ni):\n",
    "            gridcell_area[0, kk] = area\n",
    "            kk += 1\n",
    "\n",
    "    return(gridcell_area)\n",
    "\n",
    "\n",
    "def read_oce_grid(input_path_oce, grid_name_oce, verbose=False):\n",
    "    mesh=Dataset(input_path_oce+'/'+grid_name_oce+'_oifs.nc',verbose=False)\n",
    "\n",
    "    \n",
    "    # Print some info about oasis files\n",
    "    if verbose:\n",
    "        print(mesh.variables.keys())\n",
    "    \n",
    "    print(longline)\n",
    "    print(' Reading ocean grid:', grid_name_oce)\n",
    "    print(longline)\n",
    "    \n",
    "    fesom_lsm = mesh.variables['cell_area']\n",
    "    fesom_grid_sorted = fesom_lsm[:]\n",
    "\n",
    "    return fesom_grid_sorted\n",
    "\n",
    "\n",
    "def read_lsm(res_num, input_path_oifs, output_path_oifs, exp_name_oifs, num_fields,verbose=False):\n",
    "    '''\n",
    "    This function reads the oifs input file in grib format and save it into a\n",
    "    list of numpy arrays.\n",
    "    '''\n",
    "    print(' Opening Grib input file: %s ' % (input_path_oifs,))\n",
    "    input_file_oifs = input_path_oifs + 'ICMGG' + exp_name_oifs + 'INIT'\n",
    "    gid = [None] * num_fields\n",
    "    gribfield = [None] * num_fields\n",
    "    with open(input_file_oifs, 'rb') as f:\n",
    "        keys = ['N', 'shortName']\n",
    "\n",
    "        for i in range(num_fields):\n",
    "            gid[i] = gribapi.grib_new_from_file(f)\n",
    "            if gid[i] is None:\n",
    "                break\n",
    "\n",
    "            for key in keys:\n",
    "                if not gribapi.grib_is_defined(gid[i], key):\n",
    "                    raise ValueError(\"Key '%s' was not defined\" % key)\n",
    "                if verbose:\n",
    "                    print('%s=%s' % (key, gribapi.grib_get(gid[i], key)))\n",
    "\n",
    "            shortName = gribapi.grib_get(gid[i], 'shortName')\n",
    "\n",
    "            if shortName == 'lsm':\n",
    "                lsm_id = i\n",
    "            if shortName == 'slt':\n",
    "                slt_id = i\n",
    "            if shortName == 'cl':\n",
    "                cl_id = i\n",
    "\n",
    "            nres = gribapi.grib_get(gid[i], 'N')\n",
    "            gribfield[i] = gribapi.grib_get_values(gid[i])\n",
    "\n",
    "    return (gribfield, lsm_id, slt_id, cl_id, gid)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def write_lsm(gribfield_mod, input_path_oifs, output_path_oifs, exp_name_oifs,\n",
    "              grid_name_oce, num_fields, gid,verbose=False):\n",
    "    '''\n",
    "    This function copies the input gribfile to the output folder and modifies\n",
    "    it by writing the whole gribfield_mod, including the altered land sea mask\n",
    "    and soil type fields into the new file\n",
    "    '''\n",
    "\n",
    "    input_file_oifs = input_path_oifs + 'ICMGG' + exp_name_oifs + 'INIT'\n",
    "    output_file_oifs = output_path_oifs + 'ICMGG' + exp_name_oifs + 'INIT_' + grid_name_oce\n",
    "    copy2(input_file_oifs, output_file_oifs)\n",
    "\n",
    "    with open(output_file_oifs, 'r+b') as f:\n",
    "        for i in range(num_fields):\n",
    "            gribapi.grib_set_values(gid[i], gribfield_mod[i])\n",
    "            gribapi.grib_write(gid[i], f)\n",
    "            gribapi.grib_release(gid[i])\n",
    "\n",
    "\n",
    "def plotting_lsm(res_num, lsm_binary_l, lsm_binary_a, center_lats, center_lons,verbose=False):\n",
    "    '''\n",
    "    This function plots the final land sea mask\n",
    "    '''\n",
    "\n",
    "    fig3 = plt.figure(figsize=(12, 7))\n",
    "    ax3  = fig3.add_subplot(111)\n",
    "    xptsa = center_lons[np.round(lsm_binary_a[:, :])<1]\n",
    "    yptsa = center_lats[np.round(lsm_binary_a[:, :])<1]\n",
    "    xptsl = center_lons[np.round(lsm_binary_l[:, :])<1]\n",
    "    yptsl = center_lats[np.round(lsm_binary_l[:, :])<1]\n",
    "    ax3.scatter(xptsl, yptsl, s=.5, color='red', label='New dry points')\n",
    "    ax3.scatter(xptsa, yptsa, s=1, label='Wet points')\n",
    "    ax3.legend()\n",
    "    figname = 'output/plots/land_points_T%d.png' % (res_num,)\n",
    "    fig3.savefig(figname, format='png',dpi=300)\n",
    "\n",
    "\n",
    "def generate_coord_area(res_num, input_path_reduced_grid, input_path_full_grid, truncation_type, exp_name_oifs=\"hagw\",verbose=False):\n",
    "    '''\n",
    "    This function generates coordinate and areas fields based on\n",
    "    the full and reduced gaussian gridfiles for a given truncation number.\n",
    "    '''\n",
    "\n",
    "    lines, NN = read_grid_file(res_num, input_path_reduced_grid, input_path_full_grid, truncation_type, \n",
    "                               exp_name_oifs=exp_name_oifs,verbose=verbose)\n",
    "    lons_list, lats_list, numlons_list, dlon_list, lat_list = extract_grid_data(lines,verbose=verbose)\n",
    "    center_lats, center_lons, crn_lats, crn_lons = calculate_corner_latlon(lats_list, lons_list, \n",
    "                                                                           numlons_list, dlon_list, \n",
    "                                                                           lat_list,verbose=verbose)\n",
    "    gridcell_area = calculate_area(center_lons, numlons_list, dlon_list, lat_list,verbose=verbose)\n",
    "\n",
    "    return (center_lats, center_lons, crn_lats, crn_lons, gridcell_area, lons_list, NN)\n",
    "\n",
    "\n",
    "def process_lsm(res_num, input_path_oifs, output_path_oifs,\n",
    "                                 exp_name_oifs, grid_name_oce, num_fields,\n",
    "                                 fesom_grid_sorted, lons_list,\n",
    "                                 center_lats, center_lons,crn_lats, crn_lons, \n",
    "                                 gridcell_area, search_factor=1,verbose=False):\n",
    "    '''\n",
    "    This function first reads, modifies and finally saves the new land\n",
    "    sea mask. Every step is mirrored for the soil type file as it has to be\n",
    "    modified in the exact same locations\n",
    "    '''\n",
    "\n",
    "    gribfield, lsm_id, slt_id, cl_id, gid = read_lsm(res_num, input_path_oifs, \n",
    "                                                     output_path_oifs, \n",
    "                                                     exp_name_oifs, num_fields,verbose=verbose)\n",
    "    lsm_binary_a, lsm_binary_l, lsm_binary_r, gribfield_mod = modify_lsm(gribfield, \n",
    "                                                           fesom_grid_sorted, \n",
    "                                                           lsm_id, slt_id, cl_id, \n",
    "                                                           lons_list, center_lats, \n",
    "                                                           center_lons, crn_lats, crn_lons, \n",
    "                                                           gridcell_area,search_factor=search_factor,\n",
    "                                                           verbose=verbose)\n",
    "    write_lsm(gribfield_mod, input_path_oifs, output_path_oifs, exp_name_oifs, \n",
    "              grid_name_oce, num_fields, gid,verbose=verbose)\n",
    "    return (lsm_binary_a,lsm_binary_l,lsm_binary_r)\n",
    "\n",
    "\n",
    "def write_oasis_files(res_num, output_path_oasis, dir_path, grid_name_oce, center_lats, center_lons, \n",
    "                      crn_lats, crn_lons, gridcell_area, lsm_binary_a ,lsm_binary_l , lsm_binary_r, \n",
    "                      NN, input_path_runoff,verbose=False):\n",
    "    '''\n",
    "    This function writes the binary masks, areas and grids files for\n",
    "    oasis3-mct\n",
    "    For OpenIFS we set up three different grids:\n",
    "    All have the same lons, lats and areas\n",
    "    but different land-sea masks\n",
    "\n",
    "    atmo: Land = 0, Ocean = 1  (for atm->ocn fluxes)\n",
    "    atmr: Land = 1, Ocean = 0  (for atm->runoff mapper)\n",
    "\n",
    "    atmf is the fraction of ocean in each cell, but\n",
    "    IFS always has 1 or 0, so it is the same as atmo.\n",
    "    '''\n",
    "\n",
    "    for filebase in ['grids', 'areas', 'masks']:\n",
    "        filename = '%s/%s%s.nc' % (dir_path, output_path_oasis, filebase)\n",
    "        print('Writing file: %s ' % (filename,))\n",
    "        nc = Dataset(filename, 'w', clobber=True)\n",
    "\n",
    "        # For OpenIFS + NEMO + Runoffmapper we need two atmosphere grids:\n",
    "        # atmo: used for atm->ocn remapping (to find ocean)\n",
    "        # atmr: used for atm->runoff remapping (to find land)\n",
    "\n",
    "        for grids_name in ('{}{:03}'.format(s, int(NN)) for s in ('A', 'L', 'R')):\n",
    "\n",
    "            # OASIS requires certain names for the dimensions etc\n",
    "            print(' Write lons, lats, corner points for grid: %s ' % (grids_name,), '(T%s)' % (res_num,))\n",
    "            xname = 'x_%s' % (grids_name,)\n",
    "            yname = 'y_%s' % (grids_name,)\n",
    "            lonname = '%s.lon' % (grids_name,)\n",
    "            latname = '%s.lat' % (grids_name,)\n",
    "            nc.createDimension(xname, center_lons.shape[1])\n",
    "            nc.createDimension(yname, 1)\n",
    "            id_lon = nc.createVariable(lonname, 'float64', (yname, xname))\n",
    "            id_lat = nc.createVariable(latname, 'float64', (yname, xname))\n",
    "\n",
    "            # Not required, but makes grid info more readable\n",
    "            id_lon.units = 'degrees_east'\n",
    "            id_lon.standard_name = 'Longitude'\n",
    "            id_lat.units = 'degrees_north'\n",
    "            id_lat.standard_name = 'Latitude'\n",
    "\n",
    "         # Write corner points to grids file\n",
    "            if filebase == 'grids':\n",
    "                crnname = 'crn_%s' % (grids_name,)\n",
    "                cloname = '%s.clo' % (grids_name,)\n",
    "                claname = '%s.cla' % (grids_name,)\n",
    "                nc.createDimension(crnname, 4)\n",
    "                id_clo = nc.createVariable(cloname, 'float64', (crnname, yname, xname))\n",
    "                id_cla = nc.createVariable(claname, 'float64', (crnname, yname, xname))\n",
    "\n",
    "         # Write land-sea masks to masks file\n",
    "            elif filebase == 'masks':\n",
    "                mskname = '%s.msk' % (grids_name,)\n",
    "                id_msk = nc.createVariable(mskname, 'int32', (yname, xname))\n",
    "                id_msk.coordinates = '%s.lat %s.lon' % (grids_name,grids_name)\n",
    "                id_msk.valid_min = 0.\n",
    "                id_msk.valid_max = 1\n",
    "\n",
    "         # Write grid cell area to areas file\n",
    "            elif filebase == 'areas':\n",
    "                areaname = '%s.srf' % (grids_name,)\n",
    "                id_area = nc.createVariable(areaname, 'float64', (yname, xname))\n",
    "                id_area.coordinates = '%s.lat %s.lon' % (grids_name,grids_name)\n",
    "\n",
    "            id_lon[:, :] = center_lons[:, :]\n",
    "            id_lat[:, :] = center_lats[:, :]\n",
    "            id_lon.valid_min = center_lons.min()\n",
    "            id_lon.valid_max = center_lons.max()\n",
    "            id_lat.valid_min = center_lats.min()\n",
    "            id_lat.valid_max = center_lats.max()\n",
    "\n",
    "            if filebase == 'grids':\n",
    "                id_clo[:, :, :] = crn_lons[:, :, :]\n",
    "                id_cla[:, :, :] = crn_lats[:, :, :]\n",
    "                id_clo.valid_min = crn_lons.min()\n",
    "                id_clo.valid_max = crn_lons.max()\n",
    "                id_cla.valid_min = crn_lats.min()\n",
    "                id_cla.valid_max = crn_lats.max()\n",
    "\n",
    "            elif filebase == 'masks':\n",
    "                if grids_name.startswith('A') :\n",
    "                    id_msk[:, :] = np.round(lsm_binary_a[:, :])  \n",
    "                elif grids_name.startswith('L'):\n",
    "                    id_msk[:, :] = np.round(lsm_binary_l[:, :])\n",
    "                elif grids_name.startswith('R'):\n",
    "                    if grid_name_oce == 'ORCA05':\n",
    "                        id_msk[:, :] = np.abs(np.round(lsm_binary_r[:, :] - 1))\n",
    "                    else:\n",
    "                        id_msk[:, :] = np.abs(np.round(lsm_binary_a[:, :] - 1))\n",
    "                else:\n",
    "                    raise RuntimeError('Unexpected grid name: {}'.format(grids_name))\n",
    "\n",
    "            elif filebase == 'areas':\n",
    "                id_area[:, :] = gridcell_area[:, :]\n",
    "                id_area.valid_min = gridcell_area.min()\n",
    "                id_area.valid_max = gridcell_area.max()\n",
    "\n",
    "\n",
    "        # Copying runoff mapper grids and areas into oasis3-mct files\n",
    "\n",
    "        input_file_rnf = '%srunoff_%s.nc' % (input_path_runoff, filebase)\n",
    "        rnffile = Dataset(input_file_rnf, 'r')\n",
    "\n",
    "        nc.setncatts(rnffile.__dict__)\n",
    "        for name, dimension in rnffile.dimensions.items():\n",
    "            nc.createDimension(name, len(dimension) if not dimension.isunlimited() else None)\n",
    "\n",
    "        for name, variable in rnffile.variables.items():\n",
    "            var_out = nc.createVariable(name, variable.datatype, variable.dimensions)\n",
    "            var_out.setncatts({k: variable.getncattr(k) for k in variable.ncattrs()})\n",
    "            var_out[:] = variable[:]\n",
    "\n",
    "        rnffile.close()\n",
    "        nc.close()\n",
    "        print(' Wrote %s ' % (filename,))\n",
    "\n",
    "        print(longline)\n",
    "\n",
    "\n",
    "def modify_runoff_map(res_num, input_path_runoff, output_path_runoff,\n",
    "                      grid_name_oce, manual_basin_removal,verbose=False):\n",
    "    '''\n",
    "    This function generates coordinate and areas fields based on\n",
    "    the full and reduced gaussian gridfiles for a given truncation number.\n",
    "    '''\n",
    "    input_file_rnf = '%srunoff_maps.nc' % (input_path_runoff,)\n",
    "    output_file_rnf = output_path_runoff+'srunoff_maps_'+grid_name_oce+'.nc'\n",
    "    if os.path.exists(output_file_rnf):\n",
    "        os.remove(output_file_rnf)\n",
    "    copy2(input_file_rnf, output_file_rnf)\n",
    "\n",
    "    rnffile = Dataset(output_file_rnf, 'r+')\n",
    "    print (rnffile.variables.keys())\n",
    "\n",
    "    drainage = rnffile.variables[u'drainage_basin_id'][:]\n",
    "    arrival = rnffile.variables[u'arrival_point_id'][:]\n",
    "\n",
    "    # Set projection\n",
    "    lons = rnffile.variables[u'lon'][:]\n",
    "    lats = rnffile.variables[u'lat'][:]\n",
    "\n",
    "    for basin in manual_basin_removal:\n",
    "\n",
    "        if basin == 'caspian-sea':\n",
    "            for lo, lon in enumerate(lons):\n",
    "                if lon > 46 and lon < 56:\n",
    "                    for la, lat in enumerate(lats):\n",
    "                        if lat > 36 and lat < 47:\n",
    "                            if drainage[la, lo] == -2:\n",
    "                                drainage[la, lo] = 18\n",
    "                                arrival[la, lo] = -1\n",
    "                # adding artifical arrival points in the amazon discharge area\n",
    "                # to close the global water budget\n",
    "                if lon > 313 and lon < 314.5:\n",
    "                    for la, lat in enumerate(lats):\n",
    "                        if lat > 1 and lat < 2:\n",
    "                            if arrival[la, lo] != -1:\n",
    "                                arrival[la, lo] = 18\n",
    "\n",
    "        if basin == 'black-sea':\n",
    "            for lo, lon in enumerate(lons):\n",
    "                #removing old basin\n",
    "                if lon > 27 and lon < 43:\n",
    "                    for la, lat in enumerate(lats):\n",
    "                        if lat > 40.5 and lat < 48:\n",
    "                            if drainage[la, lo] == -2:\n",
    "                                drainage[la, lo] = 23\n",
    "                                arrival[la, lo] = -1\n",
    "                # adding new arrival points\n",
    "                if lon > 25 and lon < 26.5:\n",
    "                    for la, lat in enumerate(lats):\n",
    "                        if lat > 38.5 and lat < 41:\n",
    "                            if arrival[la, lo] != -1:\n",
    "                                arrival[la, lo] = 23\n",
    "                if lon > 23.5 and lon < 25:\n",
    "                    for la, lat in enumerate(lats):\n",
    "                        if lat > 38.5 and lat < 41:\n",
    "                            if arrival[la, lo] != -1:\n",
    "                                arrival[la, lo] = 28\n",
    "\n",
    "    # Fix for Ob arrival\n",
    "    for lo, lon in enumerate(lons):\n",
    "        #removing old arrival points\n",
    "        if lon > 60 and lon < 70:\n",
    "            for la, lat in enumerate(lats):\n",
    "                if lat > 60 and lat < 80:\n",
    "                    if arrival[la, lo] == 13:\n",
    "                        arrival[la, lo] = 6\n",
    "        # adding new arrival points\n",
    "        if lon > 72 and lon < 75:\n",
    "            for la, lat in enumerate(lats):\n",
    "                if lat > 65 and lat < 75:\n",
    "                    if arrival[la, lo] == 6:\n",
    "                        arrival[la, lo] = 13\n",
    "\n",
    "    # Fix for Glacial calving maps\n",
    "    # Antarctica\n",
    "    for lo, lon in enumerate(lons):\n",
    "        #removing old arrival points\n",
    "        for la, lat in enumerate(lats):\n",
    "            if lat < -55:\n",
    "                if arrival[la, lo] == 66:\n",
    "                    arrival[la, lo] = -2\n",
    "\n",
    "    for lo, lon in enumerate(lons):\n",
    "        # adding new arrival points\n",
    "        if lon > 300 and lon < 320:\n",
    "            for la, lat in enumerate(lats):\n",
    "                if lat > -70 and lat < -60:\n",
    "                    if arrival[la, lo] == -2:\n",
    "                        arrival[la, lo] = 66\n",
    "        if lon > 320 and lon < 360:\n",
    "            for la, lat in enumerate(lats):\n",
    "                if lat > -60 and lat < -50:\n",
    "                    if arrival[la, lo] == -2:\n",
    "                        arrival[la, lo] = 66\n",
    "        if lon > 170 and lon < 180:\n",
    "            for la, lat in enumerate(lats):\n",
    "                if lat > -75 and lat < -65:\n",
    "                    if arrival[la, lo] == -2:\n",
    "                        arrival[la, lo] = 66\n",
    "    # Greenland\n",
    "    for lo, lon in enumerate(lons):\n",
    "        # adding new arrival points\n",
    "        if lon > 300 and lon < 310:\n",
    "            for la, lat in enumerate(lats):\n",
    "                if lat > 50 and lat < 60:\n",
    "                    if arrival[la, lo] == -2:\n",
    "                        arrival[la, lo] = 1\n",
    "\n",
    "    # Saving results\n",
    "    rnffile.variables[u'drainage_basin_id'][:] = drainage\n",
    "    rnffile.variables[u'arrival_point_id'][:] = arrival\n",
    "    rnffile.close()\n",
    "\n",
    "    plotting_runoff(drainage, arrival, lons, lats)\n",
    "\n",
    "    return (lons, lats)\n",
    "\n",
    "\n",
    "def plotting_runoff(drainage, arrival, lons, lats,verbose=False):\n",
    "\n",
    "    # Split data and concatenate in reverse order to turn by 180° to Prime meridian\n",
    "    ds1, ds2 = np.hsplit(np.squeeze(drainage), 2)\n",
    "    drainage_cat = np.concatenate((ds2, ds1), axis=1)\n",
    "    ds1, ds2 = np.hsplit(np.squeeze(arrival), 2)\n",
    "    arrival_cat = np.concatenate((ds2, ds1), axis=1)\n",
    "\n",
    "    lons = lons-180\n",
    "    lon_0 = lons.mean()\n",
    "    lat_0 = lats.mean()\n",
    "\n",
    "    m = Basemap(llcrnrlon=-60., llcrnrlat=-10, urcrnrlon=-30., urcrnrlat=20., \\\n",
    "            resolution='l', area_thresh=1000., projection='cyl')\n",
    "\n",
    "    #Use meshgrid to create 2D arrays from coordinates\n",
    "    lon, lat = np.meshgrid(lons, lats)\n",
    "    xi, yi = m(lon, lat)\n",
    "\n",
    "    fig1 = plt.figure(figsize=(12, 8))\n",
    "    cmap = plt.cm.flag\n",
    "    cs = m.pcolor(xi, yi, arrival_cat, cmap=cmap)\n",
    "    m.drawcoastlines()\n",
    "    m.drawparallels(np.arange(-90., 120., 45.))\n",
    "    m.drawmeridians(np.arange(0., 360., 90.))\n",
    "\n",
    "    lon_0 = lons.mean()\n",
    "    lat_0 = lats.mean()\n",
    "    '''\n",
    "    m = Basemap(llcrnrlon=20., llcrnrlat=30, urcrnrlon=80., urcrnrlat=50., \\\n",
    "            resolution='l', area_thresh=1000., projection='poly', \\\n",
    "            lat_0=0., lon_0=20.)\n",
    "    #Use meshgrid to create 2D arrays from coordinates\n",
    "    lon, lat = np.meshgrid(lons, lats)\n",
    "    xi, yi = m(lon, lat)\n",
    "    fig1 = plt.figure(figsize=(12, 8))\n",
    "    cs = m.pcolor(xi, yi, drainage_cat, cmap=cmap)\n",
    "    m.drawcoastlines()\n",
    "    m.drawparallels(np.arange(-90., 120., 45.))\n",
    "    m.drawmeridians(np.arange(0., 360., 90.))\n",
    "    figname = 'output/plots/runoff_caspian_drainage.png'\n",
    "    fig1.savefig(figname, format='png')\n",
    "    fig1 = plt.figure(figsize=(12, 8))\n",
    "    cs = m.pcolor(xi, yi, arrival_cat, cmap=cmap)\n",
    "    m.drawcoastlines()\n",
    "    m.drawparallels(np.arange(-90., 120., 45.))\n",
    "    m.drawmeridians(np.arange(0., 360., 90.))\n",
    "    figname = 'output/plots/runoff_caspian_arrival.png'\n",
    "    fig1.savefig(figname, format='png')\n",
    "    '''\n",
    "\n",
    "    m = Basemap(llcrnrlon=50., llcrnrlat=40, urcrnrlon=110., urcrnrlat=80., \\\n",
    "            resolution='l', area_thresh=1000., projection='cyl')\n",
    "    fig1 = plt.figure(figsize=(12, 8))\n",
    "    cs = m.pcolor(xi, yi, drainage_cat, cmap=cmap)\n",
    "    m.drawcoastlines()\n",
    "    m.drawparallels(np.arange(-90., 120., 45.))\n",
    "    m.drawmeridians(np.arange(0., 360., 90.))\n",
    "    figname = 'output/plots/runoff_ob_drainage.png'\n",
    "    fig1.savefig(figname, format='png')\n",
    "    fig1 = plt.figure(figsize=(12, 8))\n",
    "    cs = m.pcolor(xi, yi, arrival_cat, cmap=cmap)\n",
    "    m.drawcoastlines()\n",
    "    m.drawparallels(np.arange(-90., 120., 45.))\n",
    "    m.drawmeridians(np.arange(0., 360., 90.))\n",
    "    figname = 'output/plots/runoff_ob_arrival.png'\n",
    "    fig1.savefig(figname, format='png')\n",
    "\n",
    "\n",
    "def modify_runoff_lsm(res_num, grid_name_oce, manual_basin_removal, lons, lats,\n",
    "                      output_path_oasis,verbose=False):\n",
    "    '''\n",
    "    This function generates coordinate and areas fields based on\n",
    "    the full and reduced gaussian gridfiles for a given truncation number.\n",
    "    '''\n",
    "\n",
    "    # Editing runoff mapper lsm in oasis3-mct masks file\n",
    "    filename = '%smasks.nc' % (output_path_oasis,)\n",
    "    oasis = Dataset(filename, 'r+')\n",
    "\n",
    "    RnfA = oasis.variables[u'RnfA.msk'][:]\n",
    "    RnfO = oasis.variables[u'RnfO.msk'][:]\n",
    "\n",
    "    for basin in manual_basin_removal:\n",
    "\n",
    "        if basin == 'caspian-sea':\n",
    "            for lo, lon in enumerate(lons):\n",
    "                if lon > 46 and lon < 56:\n",
    "                    for la, lat in enumerate(lats):\n",
    "                        if lat > 36 and lat < 47:\n",
    "                            RnfA[la, lo] = 0\n",
    "                            RnfO[la, lo] = 1\n",
    "\n",
    "    # Saving altered runoff mapper lsm\n",
    "    oasis.variables[u'RnfA.msk'][:] = RnfA\n",
    "    oasis.variables[u'RnfO.msk'][:] = RnfO\n",
    "    oasis.close()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def modify_lsm(gribfield, fesom_grid_sorted, lsm_id, slt_id, cl_id, lons_list, \n",
    "               center_lats, center_lons, crn_lats, crn_lons, gridcell_area,\n",
    "               search_factor=1,verbose=False):\n",
    "    '''\n",
    "    This function firstly uses the lake mask to remove lakes from the land sea\n",
    "    mask and secondly, if set, uses a preselected list of basins to manually\n",
    "    alter the lsm and slt fields further. It returns both the original mask\n",
    "    as well as the modified one\n",
    "    '''\n",
    "    # Mask with only solid land in correct format for oasis3-mct file\n",
    "    import copy\n",
    "    lsm_binary_l = copy.deepcopy(gribfield[lsm_id])\n",
    "    lsm_binary_l = lsm_binary_l[np.newaxis, :]\n",
    "    lsm_binary_r = lsm_binary_l.copy()\n",
    "\n",
    "    # Automatic lake removal with lakes mask\n",
    "    gribfield_mod = gribfield[:]\n",
    "    # Soil class of removed lakes is set to SANDY CLAY LOAM\n",
    "    for i in np.arange (0, len(gribfield_mod[slt_id])-1):\n",
    "        if gribfield_mod[cl_id][i] >= 0.5:\n",
    "            gribfield_mod[slt_id][i] = 6\n",
    "            gribfield_mod[lsm_id][i] = 1\n",
    "            \n",
    "    # default to land, as ocean will be faster to find = earlier break from loop\n",
    "    gribfield_mod[lsm_id][:] = fesom_grid_sorted\n",
    "\n",
    "    \n",
    "    # Mask with lakes counting as land in correct format for oasis3-mct file\n",
    "    lsm_binary_a = gribfield_mod[lsm_id]\n",
    "    lsm_binary_a = lsm_binary_a[np.newaxis, :]\n",
    "\n",
    "    return (lsm_binary_a,lsm_binary_l, lsm_binary_r, gribfield_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "40cd7cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                           | 0/40320 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gribfield_mod' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m             gribfield_mod[lsm_id][i_oifs] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[0;32m---> 12\u001b[0m             \u001b[43mgribfield_mod\u001b[49m[lsm_id][i_oifs] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m'''@numba.njit\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03mdef nested_loop(lons_list,fesom_grid_sorted,corner_lons,corner_lats):\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    for i_oifs in range(len(lons_list)):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03mnested_loop(lons_list,fesom_grid_sorted,corner_lons,corner_lats)'''\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m'''import dask\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03mfrom dask.delayed import delayed\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03mfrom dask.diagnostics import ProgressBar\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03mwith ProgressBar():\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    gribfield_mod_new = dask.compute(ta)'''\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gribfield_mod' is not defined"
     ]
    }
   ],
   "source": [
    "#original 26 iter /s\n",
    "\n",
    "'''    from tqdm import tqdm\n",
    "    import numba\n",
    "\n",
    "    for i_oifs in tqdm(range(len(lons_list))):\n",
    "        for i_fesom in range(len(fesom_grid_sorted)):\n",
    "            if fesom_grid_sorted[i_fesom][0] < corner_lons[i_oifs,0] and \\\n",
    "                fesom_grid_sorted[i_fesom][0] > corner_lons[i_oifs,1] and \\\n",
    "                fesom_grid_sorted[i_fesom][1] > corner_lats[i_oifs,3] and \\\n",
    "                fesom_grid_sorted[i_fesom][1] < corner_lats[i_oifs,1]:\n",
    "                gribfield_mod[lsm_id][i_oifs] = 1\n",
    "            else: \n",
    "                gribfield_mod[lsm_id][i_oifs] = 0'''\n",
    "                \n",
    "#namba 2 iter/s\n",
    "\n",
    "\n",
    "    '''@numba.njit\n",
    "    def nested_loop(lons_list,fesom_grid_sorted,corner_lons,corner_lats):\n",
    "        for i_oifs in range(len(lons_list)):\n",
    "            for i_fesom in range(len(fesom_grid_sorted)):\n",
    "                if fesom_grid_sorted[i_fesom][0] < corner_lons[i_oifs,0] and \\\n",
    "                    fesom_grid_sorted[i_fesom][0] > corner_lons[i_oifs,1] and \\\n",
    "                    fesom_grid_sorted[i_fesom][1] > corner_lats[i_oifs,3] and \\\n",
    "                    fesom_grid_sorted[i_fesom][1] < corner_lats[i_oifs,1]:\n",
    "                    gribfield_mod[lsm_id][i_oifs] = 1\n",
    "                else: \n",
    "                    gribfield_mod[lsm_id][i_oifs] = 0\n",
    "\n",
    "    nested_loop(lons_list,fesom_grid_sorted,corner_lons,corner_lats)'''\n",
    "\n",
    "#dask 0 iter/s\n",
    "\n",
    "    \n",
    "    '''import dask\n",
    "    from dask.delayed import delayed\n",
    "    from dask.diagnostics import ProgressBar\n",
    "\n",
    "    def nested_loop(lons_list,fesom_grid_sorted,corner_lons,corner_lats):\n",
    "        for i_oifs in range(len(lons_list)):\n",
    "            for i_fesom in range(len(fesom_grid_sorted)):\n",
    "                if fesom_grid_sorted[i_fesom][0] < corner_lons[i_oifs,0] and \\\n",
    "                    fesom_grid_sorted[i_fesom][0] > corner_lons[i_oifs,1] and \\\n",
    "                    fesom_grid_sorted[i_fesom][1] > corner_lats[i_oifs,3] and \\\n",
    "                    fesom_grid_sorted[i_fesom][1] < corner_lats[i_oifs,1]:\n",
    "                    gribfield_mod[lsm_id][i_oifs] = 1\n",
    "                else: \n",
    "                    gribfield_mod[lsm_id][i_oifs] = 0\n",
    "        return gribfield_mod\n",
    "\n",
    "    ta = []\n",
    "    t = dask.delayed(nested_loop)(lons_list,fesom_grid_sorted,corner_lons,corner_lats)\n",
    "    ta.append(t)\n",
    "    with ProgressBar():\n",
    "        gribfield_mod_new = dask.compute(ta)'''\n",
    "    \n",
    "    \n",
    "#Single bin 900 iter/s\n",
    "    \n",
    "    \n",
    "    '''    # some data structure setup\n",
    "    data = np.asarray(fesom_grid_sorted)\n",
    "    lons = data[:,0]\n",
    "    lats = data[:,1]\n",
    "    areas = data[:,2]\n",
    "    corner_lons = np.squeeze(np.transpose(crn_lons, (2, 0, 1)))\n",
    "    corner_lats = np.squeeze(np.transpose(crn_lats, (2, 0, 1)))\n",
    "\n",
    "    \n",
    "    \n",
    "    # specify the bin edges for the longitudes\n",
    "    lon_min = np.min(lons)\n",
    "    lon_max = np.max(lons)\n",
    "    num_bins = int(len(fesom_grid_sorted)/1000) # <- this number is an optimzation parameter\n",
    "    bin_size_lon = (lon_max - lon_min) / num_bins\n",
    "    bin_edges_lon = np.arange(lon_min, lon_max + bin_size_lon, bin_size_lon)\n",
    "    # make sure we dont miss the int. dateline\n",
    "    bin_edges_lon[0]=-180.1\n",
    "    bin_edges_lon[len(bin_edges_lon)-1]=180.1\n",
    "\n",
    "    # use digitize to get the bin indices for each lonitude value\n",
    "    bin_indices_lon = np.digitize(lons, bin_edges_lon)\n",
    "\n",
    "    # create an empty list to hold the binned data\n",
    "    binned_data_lon = [[] for _ in range(num_bins)]\n",
    "\n",
    "    # loop over the data and append each point to the appropriate bin\n",
    "    for i in range(len(data)):\n",
    "        bin_index_lon = bin_indices_lon[i] - 1\n",
    "        binned_data_lon[bin_index_lon].append(data[i])\n",
    "\n",
    "    # convert the binned data to numpy arrays\n",
    "    binned_data_lon = [np.array(bin_data_lon) for bin_data_lon in binned_data_lon]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # specify the bin edges for the latitudes\n",
    "    lat_min = np.min(lats)\n",
    "    lat_max = np.max(lats)\n",
    "    num_bins = int(len(fesom_grid_sorted)/1000) # <- this number is an optimzation parameter\n",
    "    bin_size_lat = (lat_max - lat_min) / num_bins\n",
    "    bin_edges_lat = np.arange(lat_min, lat_max + bin_size_lat, bin_size_lat)\n",
    "    # make sure we dont miss the int. dateline\n",
    "    bin_edges_lat[0]=-180.1\n",
    "    bin_edges_lat[len(bin_edges_lat)-1]=180.1\n",
    "\n",
    "    # use digitize to get the bin indices for each latitude value\n",
    "    bin_indices_lat = np.digitize(lats, bin_edges_lat)\n",
    "\n",
    "    # create an empty list to hold the binned data\n",
    "    binned_data_lat = [[] for _ in range(num_bins)]\n",
    "\n",
    "    # loop over the data and append each point to the appropriate bin\n",
    "    for i in range(len(data)):\n",
    "        bin_index_lat = bin_indices_lat[i] - 1\n",
    "        binned_data_lat[bin_index_lat].append(data[i])\n",
    "\n",
    "    # convert the binned data to numpy arrays\n",
    "    binned_data_lat = [np.array(bin_data_lat) for bin_data_lat in binned_data_lat]\n",
    "    \n",
    "\n",
    "    \n",
    "    # check if the bin is fully outside of oifs box. \n",
    "    # if it is, ignore. if it isn't continue to lat/lon check\n",
    "    print(' Looking if there is at least one ocean point within atmospheric cell')\n",
    "    print(' Searching unterneath cell and',search_factor*100,'% into neighbour cells')\n",
    "    \n",
    "    land_counter=0\n",
    "    for i_oifs in tqdm(range(len(lons_list))):\n",
    "        oifs_does_not_match_any=True\n",
    "        oifs_search_area = np.squeeze(gridcell_area[0][i_oifs])*(1+search_factor)**2\n",
    "        oce_area = 0\n",
    "        oce_num = 0\n",
    "        lat_extended_search=(corner_lats[i_oifs,1]-corner_lats[i_oifs,3])*search_factor\n",
    "        lon_extended_search=(corner_lons[i_oifs,0]-corner_lons[i_oifs,1])*search_factor\n",
    "        for i_bin_fesom in range(len(binned_data_lon)):\n",
    "            if binned_data_lon[i_bin_fesom][0][0] < corner_lons[i_oifs,0] and \\\n",
    "               binned_data_lon[i_bin_fesom][len(binned_data_lon[i_bin_fesom])-1][0] < corner_lons[i_oifs,1] or \\\n",
    "               binned_data_lon[i_bin_fesom][0][0] > corner_lons[i_oifs,0] and \\\n",
    "               binned_data_lon[i_bin_fesom][len(binned_data_lon[i_bin_fesom])-1][0] > corner_lons[i_oifs,1]:\n",
    "                continue\n",
    "            else:\n",
    "                oifs_does_not_match_any=False\n",
    "                if verbose:\n",
    "                    print('the bin:',binned_data_lon[i_bin_fesom][0][0],binned_data_lon[i_bin_fesom][1][0])\n",
    "                    print('is not fully outside of the oifs box:',corner_lons[i_oifs,0],corner_lons[i_oifs,1])\n",
    "                for i_fesom in range(len(binned_data_lon[i_bin_fesom])):\n",
    "                    if binned_data_lon[i_bin_fesom][i_fesom][1] >= corner_lats[i_oifs,3]-lat_extended_search and \\\n",
    "                       binned_data_lon[i_bin_fesom][i_fesom][1] <= corner_lats[i_oifs,1]+lat_extended_search and \\\n",
    "                       binned_data_lon[i_bin_fesom][i_fesom][0] <= corner_lons[i_oifs,0]+lon_extended_search and \\\n",
    "                       binned_data_lon[i_bin_fesom][i_fesom][0] >= corner_lons[i_oifs,1]-lon_extended_search:\n",
    "                        oce_area=oce_area+binned_data_lon[i_bin_fesom][i_fesom][2]\n",
    "                        oce_num=oce_num+1\n",
    "                        if verbose:\n",
    "                            print(oce_area, oifs_search_area)\n",
    "                            print ('found oifs coner lats:', corner_lats[i_oifs,3], corner_lats[i_oifs,1])\n",
    "                            print ('matching fesom center lat:', binned_data_lon[i_bin_fesom][i_fesom][1])\n",
    "                        if oce_area/oifs_search_area >= 0.5:\n",
    "                            gribfield_mod[lsm_id][i_oifs] = 0\n",
    "                            break\n",
    "                    else:\n",
    "                        continue\n",
    "        if oifs_does_not_match_any:\n",
    "            if verbose:\n",
    "                print ('here')\n",
    "            land_counter+=1\n",
    "    ocean_counter=len(lons_list)-land_counter\n",
    "    print('land points:',land_counter, 'ocean points:',ocean_counter, 'land fraction:', round(land_counter/len(lons_list)*100,2))\n",
    "'''\n",
    "    \n",
    "# Double binning (numerically wrong)\n",
    "    \n",
    "'''    # some data structure setup\n",
    "    data = np.asarray(fesom_grid_sorted)\n",
    "    lons = data[:,0]\n",
    "    lats = data[:,1]\n",
    "    areas = data[:,2]\n",
    "    corner_lons = np.squeeze(np.transpose(crn_lons, (2, 0, 1)))\n",
    "    corner_lats = np.squeeze(np.transpose(crn_lats, (2, 0, 1)))\n",
    "\n",
    "    \n",
    "    \n",
    "    # specify the bin edges for the longitudes\n",
    "    lon_min = np.min(lons)\n",
    "    lon_max = np.max(lons)\n",
    "    num_bins = int(len(fesom_grid_sorted)/1000) # <- this number is an optimzation parameter\n",
    "    bin_size_lon = (lon_max - lon_min) / num_bins\n",
    "    bin_edges_lon = np.arange(lon_min, lon_max + bin_size_lon, bin_size_lon)\n",
    "    # make sure we dont miss the int. dateline\n",
    "    bin_edges_lon[0]=-180.1\n",
    "    bin_edges_lon[len(bin_edges_lon)-1]=180.1\n",
    "\n",
    "    # use digitize to get the bin indices for each lonitude value\n",
    "    bin_indices_lon = np.digitize(lons, bin_edges_lon)\n",
    "\n",
    "    # create an empty list to hold the binned data\n",
    "    binned_data_lon = [[] for _ in range(num_bins)]\n",
    "\n",
    "    # loop over the data and append each point to the appropriate bin\n",
    "    for i in range(len(data)):\n",
    "        bin_index_lon = bin_indices_lon[i] - 1\n",
    "        binned_data_lon[bin_index_lon].append(data[i])\n",
    "\n",
    "    # convert the binned data to numpy arrays\n",
    "    binned_data_lon = [np.array(bin_data_lon) for bin_data_lon in binned_data_lon]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    binned_data_lat2d = [[] for _ in range(len(binned_data_lon))]\n",
    "    for n in range(len(binned_data_lon)):\n",
    "\n",
    "        lons = binned_data_lon[n][:,0]\n",
    "        lats = binned_data_lon[n][:,1]\n",
    "        areas = binned_data_lon[n][:,2]\n",
    "\n",
    "        # specify the bin edges for the latitudes\n",
    "        lon_min = np.min(lons)\n",
    "        lon_max = np.max(lons)\n",
    "\n",
    "        num_bins = int(len(binned_data_lon[n])/30) # <- this number is an optimzation parameter\n",
    "        bin_size_lat = (lat_max - lat_min) / num_bins\n",
    "        bin_edges_lat = np.arange(lat_min, lat_max + bin_size_lat, bin_size_lat)\n",
    "        bin_edges_lat[len(bin_edges_lat)-1]=90\n",
    "\n",
    "        # use digitize to get the bin indices for each latitude value\n",
    "        bin_indices_lat = np.digitize(binned_data_lon[n][:,1], bin_edges_lat)\n",
    "\n",
    "        # create an empty list to hold the binned data\n",
    "        binned_data_lat = [[] for _ in range(num_bins)]\n",
    "\n",
    "        # loop over the data and append each point to the appropriate bin\n",
    "        for i in range(len(binned_data_lon[n])):\n",
    "            bin_index_lat = bin_indices_lat[i] - 1\n",
    "            binned_data_lat[bin_index_lat].append(binned_data_lon[n][i])\n",
    "\n",
    "        # convert the binned data to numpy arrays\n",
    "        binned_data_lat = [np.array(bin_data_lat) for bin_data_lat in binned_data_lat]\n",
    "        binned_data_lat2d[n]= binned_data_lat\n",
    "\n",
    "        # Sort the array by the second column\n",
    "\n",
    "    for n in range(len(binned_data_lon)):\n",
    "        for i in range(len(binned_data_lat2d[n])):\n",
    "            arr = binned_data_lat2d[n][i]\n",
    "            if len(arr) == 0:\n",
    "                continue\n",
    "            indices = np.argsort(arr[:,1])\n",
    "            binned_data_lat2d[n][i] = arr[indices]\n",
    "            \n",
    "   \n",
    "    # check if the bin is fully outside of oifs box. \n",
    "    # if it is, ignore. if it isn't continue to lat/lon check\n",
    "    print(' Looking if there is at least one ocean point within atmospheric cell')\n",
    "    print(' Searching unterneath cell and',search_factor*100,'% into neighbour cells')\n",
    "    \n",
    "    land_counter=0\n",
    "    for i_oifs in tqdm(range(len(lons_list))):\n",
    "        oifs_does_not_match_any=True\n",
    "        oifs_search_area = np.squeeze(gridcell_area[0][i_oifs])*(1+search_factor)**2\n",
    "        oce_area = 0\n",
    "        oce_num = 0\n",
    "        lat_extended_search=(corner_lats[i_oifs,1]-corner_lats[i_oifs,3])*search_factor\n",
    "        lon_extended_search=(corner_lons[i_oifs,0]-corner_lons[i_oifs,1])*search_factor\n",
    "        for i_bin_fesom in range(len(binned_data_lon)-1):\n",
    "            if binned_data_lon[i_bin_fesom][0][0] < corner_lons[i_oifs,0] and \\\n",
    "               binned_data_lon[i_bin_fesom][len(binned_data_lon[i_bin_fesom])-1][0] < corner_lons[i_oifs,1] or \\\n",
    "               binned_data_lon[i_bin_fesom][0][0] > corner_lons[i_oifs,0] and \\\n",
    "               binned_data_lon[i_bin_fesom][len(binned_data_lon[i_bin_fesom])-1][0] > corner_lons[i_oifs,1]:\n",
    "                continue\n",
    "            else:\n",
    "                for i_bin_lat_fesom in range(len(binned_data_lat2d[i_bin_fesom])-1):\n",
    "                    try:\n",
    "                        if binned_data_lat2d[i_bin_fesom][i_bin_lat_fesom][0][1] < corner_lons[i_oifs,0] and \\\n",
    "                           binned_data_lat2d[i_bin_fesom][i_bin_lat_fesom][len(binned_data_lat2d[i_bin_fesom][i_bin_lat_fesom])-1][1] < corner_lons[i_oifs,1] or \\\n",
    "                           binned_data_lat2d[i_bin_fesom][i_bin_lat_fesom][0][1] > corner_lons[i_oifs,0] and \\\n",
    "                           binned_data_lat2d[i_bin_fesom][i_bin_lat_fesom][len(binned_data_lat2d[i_bin_fesom][i_bin_lat_fesom])-1][1] > corner_lons[i_oifs,1]:\n",
    "                            continue\n",
    "                        else:\n",
    "                            for i_fesom in range(len(binned_data_lat2d[i_bin_fesom][i_bin_lat_fesom])-1):\n",
    "                                if binned_data_lat2d[i_bin_fesom][i_bin_lat_fesom][i_fesom][1] >= corner_lats[i_oifs,3]-lat_extended_search and \\\n",
    "                                   binned_data_lat2d[i_bin_fesom][i_bin_lat_fesom][i_fesom][1] <= corner_lats[i_oifs,1]+lat_extended_search and \\\n",
    "                                   binned_data_lat2d[i_bin_fesom][i_bin_lat_fesom][i_fesom][0] <= corner_lons[i_oifs,0]+lon_extended_search and \\\n",
    "                                   binned_data_lat2d[i_bin_fesom][i_bin_lat_fesom][i_fesom][0] >= corner_lons[i_oifs,1]-lon_extended_search:\n",
    "                                    oce_area=oce_area+binned_data_lon[i_bin_fesom][i_fesom][2]\n",
    "                                    oce_num=oce_num+1\n",
    "                                    if verbose:\n",
    "                                        print(oce_area, oifs_search_area)\n",
    "                                        print ('found oifs coner lats:', corner_lats[i_oifs,3], corner_lats[i_oifs,1])\n",
    "                                        print ('matching fesom center lat:', binned_data_lon[i_bin_fesom][i_fesom][1])\n",
    "                                    if oce_area/oifs_search_area >= 0.5:\n",
    "                                        gribfield_mod[lsm_id][i_oifs] = 0\n",
    "                                        break\n",
    "                                else:\n",
    "                                    continue\n",
    "                    except:\n",
    "                        continue'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "dce3983e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " ==================================================  \n",
      "\n",
      " Reading OpenIFS gridfile for T1279 \n",
      " \n",
      " ==================================================  \n",
      "\n",
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'rline' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[637], line 61\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Loop over atmosphere resolutions. Todo: select correct exp_name_oifs\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res_num \u001b[38;5;129;01min\u001b[39;00m resolution_list:\n\u001b[1;32m     58\u001b[0m     center_lats, center_lons, \\\n\u001b[1;32m     59\u001b[0m     crn_lats, crn_lons, \\\n\u001b[1;32m     60\u001b[0m     gridcell_area, lons_list, \\\n\u001b[0;32m---> 61\u001b[0m     NN \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_coord_area\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m                             \u001b[49m\u001b[43minput_path_reduced_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_path_full_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mtruncation_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexp_name_oifs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_name_oifs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     fesom_grid_sorted \u001b[38;5;241m=\u001b[39m read_oce_grid(input_path_oce,grid_name_oce,verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m     67\u001b[0m     lsm_binary_a,lsm_binary_l,lsm_binary_r \u001b[38;5;241m=\u001b[39m process_lsm(res_num, input_path_oifs, output_path_oifs,\n\u001b[1;32m     68\u001b[0m                              exp_name_oifs, grid_name_oce, num_fields,\n\u001b[1;32m     69\u001b[0m                              fesom_grid_sorted, lons_list,\n\u001b[1;32m     70\u001b[0m                              center_lats, center_lons, crn_lats, crn_lons, \n\u001b[1;32m     71\u001b[0m                              gridcell_area, search_factor\u001b[38;5;241m=\u001b[39msearch_factor,verbose\u001b[38;5;241m=\u001b[39mverbose)\n",
      "Cell \u001b[0;32mIn[634], line 468\u001b[0m, in \u001b[0;36mgenerate_coord_area\u001b[0;34m(res_num, input_path_reduced_grid, input_path_full_grid, truncation_type, exp_name_oifs, verbose)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_coord_area\u001b[39m(res_num, input_path_reduced_grid, input_path_full_grid, truncation_type, exp_name_oifs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhagw\u001b[39m\u001b[38;5;124m\"\u001b[39m,verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m    This function generates coordinate and areas fields based on\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    the full and reduced gaussian gridfiles for a given truncation number.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m     lines, NN \u001b[38;5;241m=\u001b[39m \u001b[43mread_grid_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_path_reduced_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_path_full_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mexp_name_oifs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp_name_oifs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m     lons_list, lats_list, numlons_list, dlon_list, lat_list \u001b[38;5;241m=\u001b[39m extract_grid_data(lines,verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    471\u001b[0m     center_lats, center_lons, crn_lats, crn_lons \u001b[38;5;241m=\u001b[39m calculate_corner_latlon(lats_list, lons_list, \n\u001b[1;32m    472\u001b[0m                                                                            numlons_list, dlon_list, \n\u001b[1;32m    473\u001b[0m                                                                            lat_list,verbose\u001b[38;5;241m=\u001b[39mverbose)\n",
      "Cell \u001b[0;32mIn[634], line 92\u001b[0m, in \u001b[0;36mread_grid_file\u001b[0;34m(res_num, input_path_reduced_grid, input_path_full_grid, truncation_type, exp_name_oifs, input_path_oifs, verbose)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m    icmfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/ICMGG\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124mINIT\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (input_path_oifs, exp_name_oifs) \n\u001b[0;32m---> 92\u001b[0m    grid_txt \u001b[38;5;241m=\u001b[39m \u001b[43mread_grid_from_icmgg\u001b[49m\u001b[43m(\u001b[49m\u001b[43micmfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m    fin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(grid_txt, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     94\u001b[0m    \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Read grid from file: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (icmfile,) )\n",
      "Cell \u001b[0;32mIn[634], line 140\u001b[0m, in \u001b[0;36mread_grid_from_icmgg\u001b[0;34m(icmfile, NN, truncation_type, verbose)\u001b[0m\n\u001b[1;32m    137\u001b[0m    \u001b[38;5;66;03m# append data to latitudes list\u001b[39;00m\n\u001b[1;32m    138\u001b[0m    \u001b[38;5;28;01mfor\u001b[39;00m lat \u001b[38;5;129;01min\u001b[39;00m tmp_lat: latitudes\u001b[38;5;241m.\u001b[39mappend(lat) \n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mrline\u001b[49m,\u001b[38;5;28mlen\u001b[39m(lines)):\n\u001b[1;32m    141\u001b[0m    line \u001b[38;5;241m=\u001b[39m lines[i]\n\u001b[1;32m    142\u001b[0m    \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscanningMode\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m line: \n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'rline' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------------\n",
    "# Main Program\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    '''\n",
    "    Main program in which the tool configuration and function calls are located\n",
    "    Please configure as needed.\n",
    "    '''\n",
    "    verbose=False\n",
    "    \n",
    "    # Truncation number of desired OpenIFS grid. Multiple possible.\n",
    "    # Choose the ones you need [63, 95, 159, 255, 319, 399, 511, 799, 1279]\n",
    "    resolution_list = [1279]\n",
    "\n",
    "    # Choose type of trucation. linear or cubic-octahedral\n",
    "    truncation_type = 'cubic-octahedral'\n",
    "\n",
    "    # OpenIFS experiment name. This 4 digit code is part of the name of the\n",
    "    # ICMGG????INIT file you got from EMCWF\n",
    "    exp_name_oifs = 'hf05'#default for cubic-octahedral\n",
    "    # I have not yet found a way to determine automatically the number of\n",
    "    # fields in the ICMGG????INIT file. Set it correctly or stuff will break!\n",
    "    num_fields = 50\n",
    "\n",
    "    # Name of ocean model grid. \n",
    "    grid_name_oce = 'dart'\n",
    "    input_path_oce = 'input/fesom_mesh/'\n",
    "    \n",
    "    input_path_full_grid = 'input/gaussian_grids_full/'\n",
    "    input_path_oifs = 'input/openifs_input_default/'\n",
    "    input_path_runoff = 'input/runoff_map_default/'\n",
    "\n",
    "    # Output file directories.\n",
    "    output_path_oifs = 'output/openifs_input_modified/'\n",
    "    output_path_runoff = 'output/runoff_map_modified/'\n",
    "    output_path_oasis = 'output/oasis_mct3_input/'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Find working directory\n",
    "    dir_path = os.getcwd()\n",
    "\n",
    "        # Input file directories. Place files in appropriate subfolders or modify\n",
    "    if truncation_type == 'cubic-octahedral':\n",
    "        input_path_reduced_grid = 'input/gaussian_grids_octahedral_reduced/'\n",
    "    elif truncation_type == 'linear':\n",
    "        input_path_reduced_grid = 'input/gaussian_grids_linear_reduced/'\n",
    "    else:\n",
    "        sys.exit('truncation type not recognized')\n",
    "\n",
    "\n",
    "    # Loop over atmosphere resolutions. Todo: select correct exp_name_oifs\n",
    "    for res_num in resolution_list:\n",
    "\n",
    "        center_lats, center_lons, \\\n",
    "        crn_lats, crn_lons, \\\n",
    "        gridcell_area, lons_list, \\\n",
    "        NN = generate_coord_area(res_num,\n",
    "                                 input_path_reduced_grid, input_path_full_grid,\n",
    "                                 truncation_type,exp_name_oifs=exp_name_oifs,verbose=verbose)\n",
    "\n",
    "        fesom_grid_sorted = read_oce_grid(input_path_oce,grid_name_oce,verbose=verbose)\n",
    "        \n",
    "        lsm_binary_a,lsm_binary_l,lsm_binary_r = process_lsm(res_num, input_path_oifs, output_path_oifs,\n",
    "                                 exp_name_oifs, grid_name_oce, num_fields,\n",
    "                                 fesom_grid_sorted, lons_list,\n",
    "                                 center_lats, center_lons, crn_lats, crn_lons, \n",
    "                                 gridcell_area, search_factor=search_factor,verbose=verbose)\n",
    "\n",
    "        write_oasis_files(res_num,\n",
    "                          output_path_oasis, dir_path, grid_name_oce,\n",
    "                          center_lats, center_lons, crn_lats, crn_lons, gridcell_area,\n",
    "                          lsm_binary_a, lsm_binary_l, lsm_binary_r, NN, input_path_runoff,verbose=verbose)\n",
    "        \n",
    "        plotting_lsm(res_num, lsm_binary_l, lsm_binary_a, center_lats, center_lons,verbose=verbose)\n",
    "\n",
    "        '''lons, lats = modify_runoff_map(res_num, input_path_runoff, output_path_runoff,\n",
    "                                       grid_name_oce, manual_basin_removal,verbose=verbose)\n",
    "\n",
    "        modify_runoff_lsm(res_num, grid_name_oce, manual_basin_removal, lons, lats,\n",
    "                          output_path_oasis,verbose=verbose)'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef345b45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ocp-tool2)",
   "language": "python",
   "name": "ocp-tool2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
